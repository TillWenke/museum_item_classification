{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "import re \n",
    "from math import isnan\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype={'type': str} prevents being confused with data type for large data sets\n",
    "train = pd.read_csv('data/train.csv', index_col='id', dtype={'type': str})\n",
    "test = pd.read_csv('data/test.csv', index_col='id', dtype={'type': str})\n",
    "train_translated = pd.read_csv('data/train_translated.csv', dtype={'type': str})\n",
    "test_translated = pd.read_csv('data/test_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data = pd.read_csv('data/combined_data.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_translated = pd.read_csv('data/combined_data_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_fully_translated = pd.read_csv('data/combined_data_fully_translated.csv', index_col='id', dtype={'type': str})\n",
    "prep = pd.read_csv('data/prep.csv', index_col='id', dtype={'type': str})\n",
    "train_prep = pd.read_csv('data/train_prepared.csv', index_col='id', dtype={'type': str})\n",
    "text = pd.read_csv('data/text.csv', index_col='id', dtype={'type': str})\n",
    "train_text = pd.read_csv('data/train_text.csv', index_col='id', dtype={'type': str})\n",
    "test_text = pd.read_csv('data/test_text.csv', index_col='id', dtype={'type': str})\n",
    "#babbage = pd.read_csv('data/embedded_1k_reviews.csv', index_col='id', dtype={'type': str})\n",
    "#curie = pd.read_csv('data/curie.csv', dtype={'type': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['name', 'commentary', 'text', 'legend', 'initial_info', 'additional_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[text_features] = data[text_features].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_text(item):\n",
    "    return ' '.join(item[text_features]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_features'] = data.apply(lambda item: collect_text(item),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>commentary</th>\n",
       "      <th>text</th>\n",
       "      <th>legend</th>\n",
       "      <th>initial_info</th>\n",
       "      <th>additional_text</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232170</th>\n",
       "      <td>Kuno Areng, Bremerhaven Festwoche medal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Festwoche - Breemenhaven</td>\n",
       "      <td>KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.</td>\n",
       "      <td>Kuno Areng, Bremerhaven Festwoche medal    Festwoche - Breemenhaven KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251378</th>\n",
       "      <td>Photo-Villem Kapp, photo with dedication to Armilde M, 1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo-Villem Kapp, photo with dedication to Armilde M, 1937   Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                name  \\\n",
       "id                                                                     \n",
       "232170                       Kuno Areng, Bremerhaven Festwoche medal   \n",
       "2251378  Photo-Villem Kapp, photo with dedication to Armilde M, 1937   \n",
       "\n",
       "        commentary text  \\\n",
       "id                        \n",
       "232170         NaN  NaN   \n",
       "2251378        NaN  NaN   \n",
       "\n",
       "                                                                                      legend  \\\n",
       "id                                                                                             \n",
       "232170                                                                                   NaN   \n",
       "2251378  Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013   \n",
       "\n",
       "                     initial_info  \\\n",
       "id                                  \n",
       "232170   Festwoche - Breemenhaven   \n",
       "2251378                       NaN   \n",
       "\n",
       "                                        additional_text  \\\n",
       "id                                                        \n",
       "232170   KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.   \n",
       "2251378                                             NaN   \n",
       "\n",
       "                                                                                                                                             text_features  \n",
       "id                                                                                                                                                          \n",
       "232170                                  Kuno Areng, Bremerhaven Festwoche medal    Festwoche - Breemenhaven KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.  \n",
       "2251378  Photo-Villem Kapp, photo with dedication to Armilde M, 1937   Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['name', 'commentary', 'text', 'legend', 'initial_info', 'additional_text', 'text_features']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep.copy()\n",
    "with_damages = combined_data_fully_translated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_features = data.text_features.replace(float('nan'), ' ',)\n",
    "with_damages.damages = with_damages.damages.replace(float('nan'), ' ',)\n",
    "\n",
    "data.text_features = data.text_features + ' ' + with_damages.damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[['text_features','type','source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.to_csv('data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_features = data.text_features.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.text_features != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for type contained in texts  ~ rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "photo                                           2024\n",
       "photo negative                                  1411\n",
       "archaeological find                              789\n",
       "design/drawing/sketch                            783\n",
       "poster                                           593\n",
       "plan                                             551\n",
       "book                                             523\n",
       "letter                                           483\n",
       "manuscript                                       446\n",
       "document                                         250\n",
       "graphics                                         224\n",
       "music sheet                                      208\n",
       "seal/imprint                                     196\n",
       "coin                                             192\n",
       "script, song/vocal music                         189\n",
       "digital image                                    187\n",
       "postcard                                         126\n",
       "small print                                      102\n",
       "magazines                                        102\n",
       "medal                                             88\n",
       "audio recording                                   70\n",
       "manuscript, musical composition                   63\n",
       "invitation                                        63\n",
       "slide                                             61\n",
       "newspaper                                         52\n",
       "drawing                                           49\n",
       "telegram                                          46\n",
       "label/sign                                        43\n",
       "photo, postcard                                   43\n",
       "calendar                                          42\n",
       "caricature                                        36\n",
       "letter of honor/honorary address                  31\n",
       "musical instrument                                29\n",
       "photographic material                             29\n",
       "seal                                              27\n",
       "dish/vessel                                       26\n",
       "album                                             24\n",
       "country                                           22\n",
       "printed notes                                     21\n",
       "suit                                              20\n",
       "jewel                                             18\n",
       "crate/box                                         16\n",
       "sheet/linen                                       16\n",
       "manuscript, sheet music                           16\n",
       "paper                                             15\n",
       "sculpture                                         15\n",
       "notes                                             14\n",
       "folder/booklet                                    13\n",
       "tape/ribbon                                       13\n",
       "bag                                               11\n",
       "packaging                                         11\n",
       "letter, postcard                                  10\n",
       "certificate                                        8\n",
       "doll                                               7\n",
       "photographic negative, photographic negative       3\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data.type.unique()\n",
    "# remove nan\n",
    "types = types[:-1]\n",
    "types\n",
    "# categorize types\n",
    "types = ['photo', 'photo negative', 'photographic negative, photographic negative', 'photographic material','digital image',\\\n",
    "'archaeological find',\\\n",
    "'graphics', 'drawing', 'design/drawing/sketch','caricature','slide',\\\n",
    "'poster','plan', 'paper','notes', 'document', 'certificate',\\\n",
    "'medal', 'coin', 'label/sign',\\\n",
    "'manuscript','script, song/vocal music', 'music sheet', 'musical instrument', 'manuscript, musical composition', 'manuscript, sheet music',\\\n",
    "'postcard', 'photo, postcard', 'letter, postcard',\\\n",
    "'letter','letter of honor/honorary address',\\\n",
    "       'seal', 'seal/imprint',\\\n",
    "        'printed notes', 'small print',\\\n",
    "        'packaging', 'crate/box',\\\n",
    "        'audio recording', 'telegram',\\\n",
    "       'invitation',  'calendar',\\\n",
    "       'book','magazines', 'album', 'newspaper', 'folder/booklet',\\\n",
    "       'country',\\\n",
    "       'bag', 'suit', 'doll', 'sheet/linen', 'dish/vessel','jewel', 'tape/ribbon',\\\n",
    "       'sculpture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_features = data.text_features.replace(float('nan'), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_features</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232170</th>\n",
       "      <td>Kuno Areng, Bremerhaven Festwoche medal    Festwoche - Breemenhaven KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.</td>\n",
       "      <td>medal</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251378</th>\n",
       "      <td>Photo-Villem Kapp, photo with dedication to Armilde M, 1937   Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013</td>\n",
       "      <td>photo</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085096</th>\n",
       "      <td>Metspart, Youth Theater, 1969, in parts: Hedvig - Mari Lill, Gina - Silvia Laidla    TB080321</td>\n",
       "      <td>photo negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697904</th>\n",
       "      <td>Letter: Folk musicians: Violin: Jüri Saal: Letter to A. Pulst: 16.02.1936   Folk instrumentalists Mo238</td>\n",
       "      <td>letter</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521183</th>\n",
       "      <td>killing    treasures in a metal container</td>\n",
       "      <td>coin</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             text_features  \\\n",
       "id                                                                                                                                                           \n",
       "232170                                  Kuno Areng, Bremerhaven Festwoche medal    Festwoche - Breemenhaven KUTTER ASTARTE -SCHIFFERGILDE BREMENHAVEN E.V.   \n",
       "2251378  Photo-Villem Kapp, photo with dedication to Armilde M, 1937   Photos from the collection of Villem Kapi and Juhan Aavik\\ndesse, purchased in 2013   \n",
       "4085096                                                      Metspart, Youth Theater, 1969, in parts: Hedvig - Mari Lill, Gina - Silvia Laidla    TB080321   \n",
       "2697904                                            Letter: Folk musicians: Violin: Jüri Saal: Letter to A. Pulst: 16.02.1936   Folk instrumentalists Mo238   \n",
       "2521183                                                                                                          killing    treasures in a metal container   \n",
       "\n",
       "                   type source  \n",
       "id                              \n",
       "232170            medal  train  \n",
       "2251378           photo  train  \n",
       "4085096  photo negative  train  \n",
       "2697904          letter  train  \n",
       "2521183            coin  train  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple types in text - one type in text - one type and true type in text\n",
      "0 0 1821\n"
     ]
    }
   ],
   "source": [
    "multi_counter = 0\n",
    "one_counter = 0\n",
    "true_counter = 0\n",
    "for i, item in data.iterrows():    \n",
    "    local_counter = 0\n",
    "    pred = []\n",
    "    for type in types:            \n",
    "        if type in item.text_features:\n",
    "            local_counter += 1\n",
    "            pred.append(type)\n",
    "    if ('drawing' in item.text_features) or ('sketch' in item.text_features) or ('design' in item.text_features):\n",
    "        pred.append('design/drawing/sketch')\n",
    "        local_counter += 1\n",
    "    if local_counter > 0:\n",
    "        if pred[-1] == item.type:           \n",
    "                true_counter += 1\n",
    "    \"\"\"\n",
    "    if local_counter > 1:\n",
    "        multi_counter += 1\n",
    "    if local_counter == 1:\n",
    "        one_counter += 1\n",
    "        if pred[0] == item.type:           \n",
    "            true_counter += 1\n",
    "        else:\n",
    "            #print(pred, item.type) \n",
    "            pass\n",
    "    \"\"\"\n",
    "\n",
    "print('multiple types in text - one type in text - one type and true type in text')\n",
    "print(multi_counter, one_counter, true_counter)\n",
    "# from 14900 texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt3 embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "52\n",
      "97\n",
      "148\n",
      "185\n",
      "228\n",
      "277\n",
      "323\n",
      "359\n",
      "398\n",
      "441\n",
      "477\n",
      "512\n",
      "554\n",
      "597\n",
      "636\n",
      "675\n",
      "712\n",
      "747\n",
      "786\n",
      "831\n",
      "868\n",
      "911\n",
      "951\n",
      "997\n",
      "1046\n",
      "1097\n",
      "1137\n",
      "1172\n",
      "1209\n",
      "1254\n",
      "1293\n",
      "1327\n",
      "1362\n",
      "1409\n",
      "1448\n",
      "1483\n",
      "1530\n",
      "1573\n",
      "1608\n",
      "1639\n",
      "1681\n",
      "1725\n",
      "1769\n",
      "1805\n",
      "1857\n",
      "1905\n",
      "1946\n",
      "2000\n",
      "2042\n",
      "2081\n",
      "2124\n",
      "2158\n",
      "2193\n",
      "2225\n",
      "2264\n",
      "2304\n",
      "2355\n",
      "2394\n",
      "2436\n",
      "2479\n",
      "2513\n",
      "2555\n",
      "2596\n",
      "2629\n",
      "2668\n",
      "2709\n",
      "2759\n",
      "2809\n",
      "2839\n",
      "2884\n",
      "2927\n",
      "2963\n",
      "3010\n",
      "3054\n",
      "3103\n",
      "3152\n",
      "3198\n",
      "3246\n",
      "3296\n",
      "3338\n",
      "3379\n",
      "3425\n",
      "3466\n",
      "3512\n",
      "3548\n",
      "3591\n",
      "3640\n",
      "3681\n",
      "3720\n",
      "3766\n",
      "3821\n",
      "3862\n",
      "3904\n",
      "3948\n",
      "3989\n",
      "4034\n",
      "4078\n",
      "4117\n",
      "4147\n",
      "4178\n",
      "4212\n",
      "4250\n",
      "4280\n",
      "4324\n",
      "4370\n",
      "4406\n",
      "4436\n",
      "4484\n",
      "4518\n",
      "4559\n",
      "4595\n",
      "4648\n",
      "4683\n",
      "4722\n",
      "4754\n",
      "4805\n",
      "4852\n",
      "4900\n",
      "4950\n",
      "4988\n",
      "5036\n",
      "5072\n",
      "5119\n",
      "5157\n",
      "5196\n",
      "5224\n",
      "5257\n",
      "5298\n",
      "5350\n",
      "5394\n",
      "5427\n",
      "5468\n",
      "5513\n",
      "5554\n",
      "5592\n",
      "5640\n",
      "5679\n",
      "5718\n",
      "5754\n",
      "5801\n",
      "5850\n",
      "5898\n",
      "5934\n",
      "5975\n",
      "6022\n",
      "6054\n",
      "6106\n",
      "6142\n",
      "6177\n",
      "6220\n",
      "6260\n",
      "6299\n",
      "6326\n",
      "6378\n",
      "6423\n",
      "6459\n",
      "6506\n",
      "6549\n",
      "6592\n",
      "6637\n",
      "6677\n",
      "6725\n",
      "6764\n",
      "6807\n",
      "6860\n",
      "6900\n",
      "6952\n",
      "7001\n",
      "7035\n",
      "7076\n",
      "7125\n",
      "7166\n",
      "7213\n",
      "7264\n",
      "7309\n",
      "7354\n",
      "7404\n",
      "7449\n",
      "7483\n",
      "7524\n",
      "7559\n",
      "7593\n",
      "7633\n",
      "7682\n",
      "7736\n",
      "7775\n",
      "7814\n",
      "7862\n",
      "7907\n",
      "7956\n",
      "8002\n",
      "8042\n",
      "8073\n",
      "8111\n",
      "8158\n",
      "8204\n",
      "8245\n",
      "8272\n",
      "8314\n",
      "8352\n",
      "8397\n",
      "8433\n",
      "8470\n",
      "8516\n",
      "8565\n",
      "8600\n",
      "8629\n",
      "8664\n",
      "8712\n",
      "8757\n",
      "8783\n",
      "8833\n",
      "8879\n",
      "8927\n",
      "8965\n",
      "9005\n",
      "9041\n",
      "9089\n",
      "9137\n",
      "9174\n",
      "9224\n",
      "9265\n",
      "9304\n",
      "9339\n",
      "9376\n",
      "9416\n",
      "9452\n",
      "9488\n",
      "9518\n",
      "9556\n",
      "9605\n",
      "9645\n",
      "9683\n",
      "9723\n",
      "9756\n",
      "9803\n",
      "9845\n",
      "9886\n",
      "9925\n",
      "9968\n",
      "10004\n",
      "10044\n",
      "10088\n",
      "10120\n",
      "10162\n",
      "10205\n",
      "10244\n",
      "10284\n",
      "10331\n",
      "10374\n",
      "10413\n",
      "10446\n",
      "10485\n",
      "10522\n",
      "10564\n",
      "10604\n",
      "10643\n",
      "10689\n",
      "10739\n",
      "10777\n",
      "10820\n",
      "10856\n",
      "10893\n",
      "10935\n",
      "10967\n",
      "11008\n",
      "11049\n",
      "11101\n",
      "11145\n",
      "11196\n",
      "11228\n",
      "11259\n",
      "11308\n",
      "11351\n",
      "11388\n",
      "11430\n",
      "11462\n",
      "11503\n",
      "11546\n",
      "11569\n",
      "11612\n",
      "11656\n",
      "11703\n",
      "11743\n",
      "11780\n",
      "11826\n",
      "11864\n",
      "11910\n",
      "11960\n",
      "12002\n",
      "12034\n",
      "12082\n",
      "12111\n",
      "12146\n",
      "12198\n",
      "12240\n",
      "12284\n",
      "12328\n",
      "12380\n",
      "12421\n",
      "12461\n",
      "12489\n",
      "12532\n",
      "12576\n",
      "12621\n",
      "12663\n",
      "12704\n",
      "12744\n",
      "12791\n",
      "12833\n",
      "12867\n",
      "12919\n",
      "12964\n",
      "13003\n",
      "13047\n",
      "13083\n",
      "13106\n",
      "13140\n",
      "13179\n",
      "13203\n",
      "13237\n",
      "13267\n",
      "13304\n",
      "13335\n",
      "13376\n",
      "13412\n",
      "13445\n",
      "13489\n",
      "13522\n",
      "13565\n",
      "13597\n",
      "13636\n",
      "13692\n",
      "13733\n",
      "13772\n",
      "13814\n",
      "13865\n",
      "13910\n",
      "13951\n",
      "13993\n",
      "14035\n",
      "14073\n",
      "14111\n",
      "14140\n",
      "14189\n",
      "14229\n",
      "14270\n",
      "14316\n",
      "14366\n",
      "14409\n",
      "14443\n",
      "14482\n",
      "14520\n",
      "14554\n",
      "14596\n",
      "14639\n",
      "14674\n",
      "14710\n",
      "14755\n",
      "14793\n",
      "14826\n",
      "14875\n",
      "14921\n",
      "14960\n",
      "14994\n",
      "15046\n",
      "15072\n",
      "15122\n",
      "15167\n",
      "15218\n",
      "15262\n",
      "15316\n",
      "15353\n",
      "15401\n",
      "15433\n",
      "15482\n",
      "15521\n",
      "15551\n",
      "15598\n",
      "15642\n",
      "15685\n",
      "15720\n",
      "15761\n",
      "15806\n",
      "15847\n",
      "15889\n",
      "15926\n",
      "15973\n",
      "16010\n",
      "16047\n",
      "16088\n",
      "16132\n",
      "16173\n",
      "16213\n",
      "16264\n",
      "16296\n",
      "16342\n",
      "16382\n",
      "16430\n",
      "16475\n",
      "16516\n",
      "16559\n",
      "16600\n",
      "16637\n",
      "16685\n",
      "16717\n",
      "16756\n",
      "16799\n",
      "16840\n",
      "16891\n",
      "16928\n",
      "16965\n",
      "17016\n",
      "17046\n",
      "17093\n",
      "17137\n",
      "17181\n",
      "17212\n",
      "17263\n",
      "17308\n",
      "17343\n",
      "17390\n",
      "17429\n",
      "17468\n",
      "17495\n",
      "17548\n",
      "17590\n",
      "17635\n",
      "17665\n",
      "17702\n",
      "17749\n",
      "17780\n",
      "17823\n",
      "17866\n",
      "17901\n",
      "17941\n",
      "17975\n",
      "18018\n",
      "18058\n",
      "18097\n",
      "18138\n",
      "18180\n",
      "18227\n",
      "18278\n",
      "18320\n",
      "18356\n",
      "18396\n",
      "18434\n",
      "18484\n",
      "18534\n",
      "18579\n",
      "18613\n",
      "18653\n",
      "18685\n",
      "18730\n",
      "18782\n",
      "18827\n",
      "18868\n",
      "18921\n",
      "18965\n",
      "19011\n",
      "19050\n",
      "19085\n",
      "19129\n",
      "19166\n",
      "19207\n",
      "19253\n",
      "19290\n",
      "19339\n",
      "19379\n",
      "19428\n",
      "19466\n",
      "19514\n",
      "19544\n",
      "19583\n",
      "19623\n",
      "19672\n",
      "19717\n",
      "19757\n",
      "19792\n",
      "19834\n",
      "19872\n",
      "19920\n",
      "19958\n",
      "19991\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "openai.api_key = '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'\n",
    "count = 0\n",
    "def get_embedding(text, model=\"text-similarity-davinci-001\"):\n",
    "    global count\n",
    "    count += 1\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        result = openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "    except:\n",
    "        print(count)\n",
    "        time.sleep(60)\n",
    "        result = openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "    return result\n",
    " \n",
    "text['curie_similarity'] = text.text_features.apply(lambda x: get_embedding(x, model='text-similarity-curie-001'))\n",
    "text.to_csv('data/curie.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curie.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = df[df.source == 'train']\n",
    "test_emb = df[df.source == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb.to_csv('data/train_curie.csv', index=True)\n",
    "test_emb.to_csv('data/test_curie.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rf on embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_curie.csv', index_col='id', dtype={'type': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['curie_similarity'] = df.curie_similarity.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "features = list(df.curie_similarity.values)\n",
    "labels = df.type\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "import re \n",
    "from math import isnan\n",
    "import wandb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "\n",
    "df = pd.read_csv('data/train_curie.csv', index_col='id', dtype={'type': str})\n",
    "df['curie_similarity'] = df.curie_similarity.apply(eval).apply(np.array)\n",
    "print('eval')\n",
    "\n",
    "features = list(df.curie_similarity.values)\n",
    "labels = df.type\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0)\n",
    "\n",
    "bst = XGBClassifier(random_state=0)\n",
    "print('run')\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0.01085097 0.01198783 0.00867431 ... 0.0049957  0.02543602 0.01269028]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/nlp.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m preds \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m probas \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0.01085097 0.01198783 0.00867431 ... 0.0049957  0.02543602 0.01269028]'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    " \n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/nlp.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/nlp.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf\u001b[39m.\u001b[39msave_model(\u001b[39m'\u001b[39m\u001b[39mmodels/curie_model.json\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.save_model('models/curie_model.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
