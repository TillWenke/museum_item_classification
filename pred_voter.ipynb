{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_general import *\n",
    "from setup_embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_indicators = {}\n",
    "with open('data/type_indicators/type_ind_cut.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        type_indicators[type] = indicators\n",
    "save_indicators = {}\n",
    "with open('data/type_indicators/save_indicator.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        save_indicators[type] = indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive functions for type from text keywords\n",
    "\n",
    "def filtering(text):\n",
    "    pred = []\n",
    "    for type in types:            \n",
    "        if type in text:\n",
    "            pred.append(type)\n",
    "    if ('drawing' in text) or ('sketch' in text) or ('design' in text):\n",
    "        pred.append('design/drawing/sketch')\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        for indicator in type_indicators[type]:\n",
    "            if indicator in text:\n",
    "                pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def save_indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        if type in save_indicators.keys():\n",
    "            for indicator in save_indicators[type]:\n",
    "                if indicator in text:\n",
    "                    pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine models via class-probability combination (soft-voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the full ds used for submission?\n",
    "full = False\n",
    "# submit to \n",
    "sub_name = 'class_adding_best_kaggle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "#define models to be used for testing use 03 for submission use full\n",
    "import pickle\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('models/xg/03_smote100.json')\n",
    "\n",
    "rf = pickle.load(open('./models/rf/train_prep_full_best' , 'rb'))\n",
    "\n",
    "boost_emb = XGBClassifier()\n",
    "boost_emb.load_model('models/nlp/xgboost_03.json')\n",
    "\n",
    "nn = TabNetClassifier()\n",
    "nn.load_model('models/nn/tabnet_03.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_prep.copy() if full else train_prep.copy()\n",
    "\n",
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)\n",
    "if full: X_test = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = X_test.index\n",
    "results.set_index('id', inplace=True)\n",
    "if not full: results['type'] = y_test\n",
    "\n",
    "#results['rf'] = rf.predict(X_test)\n",
    "results['nn'] = nn.predict(X_test.values)\n",
    "#results['xg'] = xgb.predict_proba(X_test)\n",
    "\n",
    "results['filter'] = [-1] * len(results)\n",
    "results['indi'] = [-1] * len(results)\n",
    "results['save'] = [-1] * len(results)\n",
    "results['emb'] = [[-1]] * len(results)\n",
    "\n",
    "\n",
    "results['xg'] = [[-1]] * len(results)\n",
    "results['rf'] = [[-1]] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7202/1817881700.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['xg'].iloc[i] = np.array(item)\n",
      "/tmp/ipykernel_7202/1817881700.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['rf'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(xgb.predict_proba(X_test)):\n",
    "    results['xg'].iloc[i] = np.array(item)\n",
    "\n",
    "for i,item in enumerate(rf.predict_proba(X_test)):\n",
    "    results['rf'].iloc[i] = np.array(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_curie.copy() if full else train_curie.copy()\n",
    "\n",
    "features = list(text.curie_similarity.values)\n",
    "labels = text.type\n",
    "\n",
    "#text['pred'] = boost_emb.predict_proba(features)\n",
    "text['pred'] = [[-1]] * len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,item in enumerate(boost_emb.predict_proba(features)):\n",
    "    text['pred'].iloc[i] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish our own rules to determine type from text - eventually not beneficial\n",
    "text['filter'] = text.text_features.apply(filtering) # check for the type in the text\n",
    "text['indicating'] = text.text_features.apply(indicating) # check for other often occuring type indicating words\n",
    "text['save'] = text.text_features.apply(save_indicating) # only check for words that (almost) only occur with a certain type\n",
    "\n",
    "text['filter'] = text['filter'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['indicating'] = text['indicating'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['save'] = text['save'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "\n",
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'filter'] = item['filter']\n",
    "            results.at[index, 'indi'] = item['indicating']\n",
    "            results.at[index, 'save'] = item['save']\n",
    "            results.at[index, 'emb'] = item['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evalaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statistics import mode\\ndef vote(predictions):\\n    if predictions[0] != -1:\\n        return predictions[0]\\n    if -1 in predictions: predictions.remove(-1)\\n    return mode(predictions)\\n\\nresults['prediction'] = results.apply(lambda row: vote([row.save,row.xg,row.rf,row.emb]), axis=1)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from previous approach for hard voting on predicted classes\n",
    "\"\"\"\n",
    "from statistics import mode\n",
    "def vote(predictions):\n",
    "    if predictions[0] != -1:\n",
    "        return predictions[0]\n",
    "    if -1 in predictions: predictions.remove(-1)\n",
    "    return mode(predictions)\n",
    "\n",
    "results['prediction'] = results.apply(lambda row: vote([row.save,row.xg,row.rf,row.emb]), axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def vote(preds):\n",
    "    xg = np.array(preds[0])\n",
    "    emb = np.array(preds[1])\n",
    "    if emb[0] != -1:\n",
    "        res = xg + emb\n",
    "    else:\n",
    "        res = xg\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       1.00      1.00      1.00       240\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.98      0.99      0.99       162\n",
      "           5       1.00      1.00      1.00        11\n",
      "           6       1.00      0.94      0.97        17\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00        52\n",
      "           9       1.00      0.86      0.92         7\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      0.98      0.99       270\n",
      "          12       1.00      1.00      1.00        57\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       0.95      0.89      0.92       125\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       1.00      0.95      0.97        20\n",
      "          17       0.60      1.00      0.75         3\n",
      "          18       0.97      1.00      0.98        62\n",
      "          19       0.77      0.77      0.77        30\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       1.00      1.00      1.00        10\n",
      "          22       0.91      0.93      0.92       197\n",
      "          23       1.00      0.80      0.89        10\n",
      "          24       1.00      0.83      0.91         6\n",
      "          25       0.97      0.94      0.95        33\n",
      "          26       0.98      0.98      0.98       163\n",
      "          27       1.00      1.00      1.00        22\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       1.00      1.00      1.00        30\n",
      "          30       1.00      1.00      1.00        61\n",
      "          31       1.00      1.00      1.00         8\n",
      "          32       0.86      0.91      0.89        34\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      0.50      0.67         2\n",
      "          35       1.00      0.80      0.89         5\n",
      "          36       0.98      1.00      0.99      1067\n",
      "          37       0.99      1.00      0.99       685\n",
      "          38       1.00      0.88      0.93        16\n",
      "          39       1.00      1.00      1.00         9\n",
      "          40       0.00      0.00      0.00         5\n",
      "          41       0.95      0.98      0.97       213\n",
      "          42       0.97      0.75      0.85        48\n",
      "          43       1.00      1.00      1.00       237\n",
      "          44       1.00      1.00      1.00         6\n",
      "          45       1.00      1.00      1.00        48\n",
      "          46       1.00      0.67      0.80         6\n",
      "          47       1.00      1.00      1.00        10\n",
      "          48       1.00      1.00      1.00        63\n",
      "          49       1.00      1.00      1.00         3\n",
      "          50       1.00      1.00      1.00        19\n",
      "          51       1.00      0.96      0.98        27\n",
      "          52       1.00      1.00      1.00         5\n",
      "          53       1.00      1.00      1.00         3\n",
      "          54       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.98      4200\n",
      "   macro avg       0.96      0.93      0.94      4200\n",
      "weighted avg       0.98      0.98      0.98      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results['prediction'] = results.apply(lambda row: vote([row.xg,row.emb]), axis=1)\n",
    "if not full:\n",
    "    print(accuracy_score(results.type, results.prediction))\n",
    "    print(classification_report(results.type, results.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full:\n",
    "    submission = pd.DataFrame({'id': results.index ,'type': results.prediction})\n",
    "    submission = submission.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "    submission.to_csv(f'submissions/{sub_name}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
