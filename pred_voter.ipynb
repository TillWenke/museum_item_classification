{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_general import *\n",
    "from setup_embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_indicators = {}\n",
    "with open('data/type_indicators/type_ind_cut.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        type_indicators[type] = indicators\n",
    "save_indicators = {}\n",
    "with open('data/type_indicators/save_indicator.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        save_indicators[type] = indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive functions for type from text keywords\n",
    "\n",
    "def filtering(text):\n",
    "    pred = []\n",
    "    for type in types:            \n",
    "        if type in text:\n",
    "            pred.append(type)\n",
    "    if ('drawing' in text) or ('sketch' in text) or ('design' in text):\n",
    "        pred.append('design/drawing/sketch')\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        for indicator in type_indicators[type]:\n",
    "            if indicator in text:\n",
    "                pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def save_indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        if type in save_indicators.keys():\n",
    "            for indicator in save_indicators[type]:\n",
    "                if indicator in text:\n",
    "                    pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine models via class-probability combination (soft-voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the full ds used for submission?\n",
    "full = True\n",
    "# submit to \n",
    "sub_name = 'kaspar_type_checks_xgrfnn_no_emb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "#define models to be used for testing use 03 for submission use full\n",
    "import pickle\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('models/xg/full_smote100.json')\n",
    "\n",
    "rf = pickle.load(open('./models/rf/train_prep_full_best' , 'rb'))\n",
    "\n",
    "boost_emb = XGBClassifier()\n",
    "boost_emb.load_model('models/nlp/bal_full_xg_emb.json')\n",
    "\n",
    "nn = TabNetClassifier()\n",
    "nn.load_model('models/nn/tabnet_full.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_prep.copy() if full else train_prep.copy()\n",
    "\n",
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)\n",
    "if full: X_test = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = X_test.index\n",
    "results.set_index('id', inplace=True)\n",
    "if not full: results['type'] = y_test\n",
    "\n",
    "#results['rf'] = rf.predict(X_test)\n",
    "#results['xg'] = xgb.predict_proba(X_test)\n",
    "#results['nn'] = nn.predict(X_test.values)\n",
    "\n",
    "results['filter'] = [-1] * len(results)\n",
    "results['indi'] = [-1] * len(results)\n",
    "results['save'] = [-1] * len(results)\n",
    "results['emb'] = [[-1]] * len(results)\n",
    "\n",
    "\n",
    "results['xg'] = [[-1]] * len(results)\n",
    "results['rf'] = [[-1]] * len(results)\n",
    "results['nn'] = [[-1]] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9834/1971795648.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['xg'].iloc[i] = np.array(item)\n",
      "/tmp/ipykernel_9834/1971795648.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['rf'].iloc[i] = np.array(item)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/pred_voter.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     results[\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(item)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(nn\u001b[39m.\u001b[39mpredict_proba(X_test\u001b[39m.\u001b[39mvalues)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     results[\u001b[39m'\u001b[39;49m\u001b[39mnn\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39miloc[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(item)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nn'"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(xgb.predict_proba(X_test)):\n",
    "    results['xg'].iloc[i] = np.array(item)\n",
    "\n",
    "for i,item in enumerate(rf.predict_proba(X_test)):\n",
    "    results['rf'].iloc[i] = np.array(item)\n",
    "\n",
    "for i,item in enumerate(nn.predict_proba(X_test.values)):\n",
    "    results['nn'].iloc[i] = np.array(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_curie.copy() if full else train_curie.copy()\n",
    "\n",
    "features = text.drop('type', axis=1)\n",
    "labels = text.type\n",
    "\n",
    "#text['pred'] = boost_emb.predict_proba(features)\n",
    "text['pred'] = [[-1]] * len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9834/2524059003.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['pred'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(boost_emb.predict_proba(features)):\n",
    "    text['pred'].iloc[i] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# establish our own rules to determine type from text - eventually not beneficial\\ntext['filter'] = text.text_features.apply(filtering) # check for the type in the text\\ntext['indicating'] = text.text_features.apply(indicating) # check for other often occuring type indicating words\\ntext['save'] = text.text_features.apply(save_indicating) # only check for words that (almost) only occur with a certain type\\n\\ntext['filter'] = text['filter'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\ntext['indicating'] = text['indicating'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\ntext['save'] = text['save'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\n\\nfor index, item in text.iterrows():\\n        if index in results.index:\\n            results.at[index, 'filter'] = item['filter']\\n            results.at[index, 'indi'] = item['indicating']\\n            results.at[index, 'save'] = item['save']\\n            results.at[index, 'emb'] = item['pred']\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# establish our own rules to determine type from text - eventually not beneficial\n",
    "text['filter'] = text.text_features.apply(filtering) # check for the type in the text\n",
    "text['indicating'] = text.text_features.apply(indicating) # check for other often occuring type indicating words\n",
    "text['save'] = text.text_features.apply(save_indicating) # only check for words that (almost) only occur with a certain type\n",
    "\n",
    "text['filter'] = text['filter'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['indicating'] = text['indicating'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['save'] = text['save'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "\n",
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'filter'] = item['filter']\n",
    "            results.at[index, 'indi'] = item['indicating']\n",
    "            results.at[index, 'save'] = item['save']\n",
    "            results.at[index, 'emb'] = item['pred']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'emb'] = item['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evalaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def vote(preds):\n",
    "    if preds[-1][0] == -1:\n",
    "        preds = preds[:-1]\n",
    "    res = np.sum(preds, axis=0)\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/pred_voter.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: vote([row\u001b[39m.\u001b[39;49mxg, row\u001b[39m.\u001b[39;49mrf, row\u001b[39m.\u001b[39;49mnn]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m full:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(accuracy_score(results\u001b[39m.\u001b[39mtype, results\u001b[39m.\u001b[39mprediction))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:9558\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9547\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9549\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9550\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9551\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9556\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9557\u001b[0m )\n\u001b[0;32m-> 9558\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:741\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:868\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 868\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    870\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:884\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    883\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 884\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    885\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    886\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    887\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    888\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/pred_voter.ipynb Cell 17\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: vote([row\u001b[39m.\u001b[39;49mxg, row\u001b[39m.\u001b[39;49mrf, row\u001b[39m.\u001b[39;49mnn]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m full:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(accuracy_score(results\u001b[39m.\u001b[39mtype, results\u001b[39m.\u001b[39mprediction))\n",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/pred_voter.ipynb Cell 17\u001b[0m in \u001b[0;36mvote\u001b[0;34m(preds)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvote\u001b[39m(preds):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m preds[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         preds \u001b[39m=\u001b[39m preds[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_voter.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(preds, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "results['prediction'] = results.apply(lambda row: vote([row.xg, row.rf, row.nn]), axis=1)\n",
    "if not full:\n",
    "    print(accuracy_score(results.type, results.prediction))\n",
    "    print(classification_report(results.type, results.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == np.array([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to numeric\n",
    "def replace_value(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return np.float64(value.replace(',', '.'))\n",
    "\n",
    "\n",
    "# convert to numeric and only keep year part\n",
    "def replace_start_end(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    if re.match('^d?ddd$', value):\n",
    "        return int(value)\n",
    "    if re.match('dddd$', value):\n",
    "        return int(value[-4:])\n",
    "    elif not value[0].isdigit():\n",
    "        return int(f'19{value[-2:]}')\n",
    "    else:\n",
    "        return nan\n",
    "\n",
    "\n",
    "def extract_year_from_name(row):\n",
    "    name = row['name']\n",
    "    start = row['start']\n",
    "    if pd.isnull(start) and not pd.isnull(name):\n",
    "        match = re.search('\\d\\d\\d\\d', name)\n",
    "        if match:\n",
    "            start = match.group()\n",
    "    return start\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, submission=False):\n",
    "    categorical_cols = ['material', 'location', 'before_Christ', 'country_and_unit', 'technique', 'parameter',\n",
    "                        'museum_abbr', 'damages', 'state', 'color', 'event_type', 'collection_mark']\n",
    "    categorical_cols += ['unit', 'participants_role', 'participant', 'musealia_mark']\n",
    "\n",
    "    # just keeping track what values are used\n",
    "    numeric_cols = ['start', 'end', 'value', 'collection_queue_nr', 'is_original', 'ks', 'element_count',\n",
    "                    'musealia_seria_nr', 'musealia_queue_nr']\n",
    "\n",
    "    dropped_cols = ['id', 'parish']  # can't use\n",
    "    dropped_cols += ['full_nr', 'class', 'collection_additional_nr', 'additional_text', 'text', 'initial_info',\n",
    "                     'musealia_additional_nr']  # 'commentary','name', 'legend'\n",
    "\n",
    "    if not submission: dropped_cols.append('type')\n",
    "\n",
    "    df['start'] = df['start'].apply(replace_start_end)\n",
    "    df['end'] = df['end'].apply(replace_start_end)\n",
    "    df['value'] = df['value'].apply(replace_value)\n",
    "    df['start'] = df[['name', 'start']].apply(extract_year_from_name, axis=1)\n",
    "\n",
    "    df = df.drop(columns=dropped_cols)\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_label_from_comment(row):\n",
    "    # comment #################################################\n",
    "    comment = row['commentary']\n",
    "\n",
    "    if not pd.isnull(comment):\n",
    "        comment = str(comment).lower()\n",
    "\n",
    "        comment_dict = {\n",
    "            'lakk': 'pitser/templijäljend',\n",
    "            'must-valge negatiiv': 'fotonegatiiv',\n",
    "            'pitserilakk': 'pitser/templijäljend',\n",
    "            'käepide': 'pitsat',\n",
    "            'перф': 'fotonegatiiv',\n",
    "            'fotoemulsioon': 'fotomaterjal',\n",
    "            'plakat':'plakat'\n",
    "        }\n",
    "        for key, val in comment_dict.items():\n",
    "            if comment.startswith(key):\n",
    "                return val\n",
    "\n",
    "        if re.match('^\\d,\\d\\d\\sg$', comment):\n",
    "            return 'münt'\n",
    "\n",
    "        if 'diapositiiv' in comment:\n",
    "            return 'diapositiiv'\n",
    "\n",
    "    # name #################################################\n",
    "    name = row['name']\n",
    "\n",
    "    if not pd.isnull(name):\n",
    "        name = str(name).lower()\n",
    "        if name == ['denaar', 'killing', 'penn', 'schilling', '1/2 örtug', 'dirhem', 'fyrk']:\n",
    "            return 'münt'\n",
    "\n",
    "        for val in ['medal', 'plakat', 'märkmed', 'maal', 'kiri', 'kleit', 'kava', 'joonistus', 'graafika', 'dokument',\n",
    "                    'ajakiri', 'telegramm', 'skulptuur', 'raamat', 'postkaart', 'nukk', 'skulptuur', 'käsikiri']:\n",
    "            if name.startswith(val):\n",
    "                return val\n",
    "\n",
    "        name_dict = {\n",
    "            'kaustik': 'kaustik/vihik',\n",
    "            'vihik': 'kaustik/vihik',\n",
    "            'reprofoto': 'diapositiiv',\n",
    "        }\n",
    "        for key, val in name_dict.items():\n",
    "            if name.startswith(key):\n",
    "                return val\n",
    "    return nan\n",
    "\n",
    "def replace_predictions(labels, pred):\n",
    "    result = np.array(pred, copy=True)\n",
    "    for i, label in enumerate(labels):\n",
    "        if not pd.isnull(label) and label != 0:\n",
    "            result[i] = label\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kutse kiri\n",
      "käsikiri kiri\n",
      "foto diapositiiv\n",
      "dokument kaustik/vihik\n",
      "foto postkaart\n",
      "pitsat pitser/templijäljend\n",
      "kiri postkaart\n",
      "kiri käsikiri\n",
      "fotonegatiiv maal\n",
      "lina/linik kleit\n",
      "märkmed käsikiri\n",
      "kiri postkaart\n",
      "dokument kava\n",
      "kiri postkaart\n",
      "kutse kava\n",
      "kava kiri\n",
      "postkaart kiri\n",
      "käsikiri plakat\n",
      "telegramm kiri\n",
      "kiri postkaart\n",
      "aukiri/auaadress raamat\n",
      "aukiri/auaadress kiri\n",
      "foto, postkaart postkaart\n",
      "kiri, postkaart kiri\n",
      "joonistus graafika\n",
      "väiketrükis kiri\n",
      "kiri postkaart\n",
      "dokument kiri\n",
      "märkmed käsikiri\n",
      "kiri dokument\n",
      "silt/märk pitsat\n",
      "aukiri/auaadress kiri\n",
      "foto kiri\n",
      "dokument telegramm\n",
      "käsikiri, laul/ vokaalmuusika käsikiri\n",
      "käsikiri telegramm\n",
      "käsikiri märkmed\n",
      "aukiri/auaadress kiri\n",
      "aukiri/auaadress kiri\n",
      "kiri postkaart\n",
      "kaustik/vihik kiri\n",
      "kutse kiri\n",
      "graafika joonistus\n",
      "foto kava\n",
      "dokument kiri\n",
      "raamat ajakiri\n",
      "kiri kava\n",
      "foto kava\n",
      "märkmed käsikiri\n",
      "dokument kiri\n",
      "telegramm kiri\n",
      "postkaart kiri\n",
      "kiri telegramm\n",
      "käsikiri dokument\n",
      "postkaart kiri\n",
      "ajaleht dokument\n",
      "käsikiri, muusikateos käsikiri\n",
      "foto postkaart\n",
      "dokument kiri\n",
      "märkmed dokument\n",
      "dokument kiri\n",
      "foto diapositiiv\n",
      "pitser/templijäljend pitsat\n",
      "kava dokument\n",
      "kavand/joonis/eskiis plakat\n",
      "kiri postkaart\n",
      "kiri postkaart\n",
      "kutse kava\n",
      "kiri postkaart\n",
      "kutse kiri\n",
      "foto, postkaart postkaart\n",
      "dokument kiri\n",
      "kiri, postkaart kiri\n",
      "dokument kaustik/vihik\n",
      "aukiri/auaadress kiri\n",
      "dokument märkmed\n",
      "silt/märk nukk\n",
      "album dokument\n",
      "kiri käsikiri\n",
      "dokument käsikiri\n",
      "postkaart kiri\n",
      "dokument kiri\n",
      "kiri käsikiri\n",
      "postkaart kiri\n",
      "postkaart kiri\n",
      "dokument kiri\n",
      "joonistus graafika\n",
      "postkaart kiri\n",
      "kiri kava\n",
      "foto fotomaterjal\n",
      "käsikiri dokument\n",
      "kava käsikiri\n",
      "aukiri/auaadress kiri\n",
      "foto postkaart\n",
      "kiri postkaart\n",
      "aukiri/auaadress kiri\n",
      "graafika maal\n",
      "foto diapositiiv\n",
      "telegramm kiri\n",
      "dokument kiri\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "\n",
    "if full:\n",
    "    results.prediction = results.prediction.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "    #results = results.assign(prediction='foto')\n",
    "\n",
    "    a = results.prediction.copy().tolist()\n",
    "\n",
    "    df_submission = pd.read_csv(\"data/general/test.csv\")\n",
    "    x2 = preprocess_dataframe(df_submission, submission=True)\n",
    "    # reorder columns + add missing columns + remove extra columns\n",
    "    x2_labels = x2.apply(extract_label_from_comment, axis=1)\n",
    "    \n",
    "\n",
    "    results.prediction = replace_predictions(x2_labels, results.prediction)\n",
    "    submission = pd.DataFrame({'id': results.index ,'type': results.prediction})\n",
    "\n",
    "    b = results.prediction.copy().tolist()\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            count += 1\n",
    "            print(a[i], b[i])\n",
    "\n",
    "    print(count)\n",
    "\n",
    "\n",
    "    #submission.groupby('type').nunique()  # predicted classes\n",
    "\n",
    "    submission.to_csv(f'submissions/{sub_name}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
