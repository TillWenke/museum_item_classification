{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_general import *\n",
    "from setup_embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_indicators = {}\n",
    "with open('data/type_indicators/type_ind_cut.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        type_indicators[type] = indicators\n",
    "save_indicators = {}\n",
    "with open('data/type_indicators/save_indicator.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        save_indicators[type] = indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive functions for type from text keywords\n",
    "\n",
    "def filtering(text):\n",
    "    pred = []\n",
    "    for type in types:            \n",
    "        if type in text:\n",
    "            pred.append(type)\n",
    "    if ('drawing' in text) or ('sketch' in text) or ('design' in text):\n",
    "        pred.append('design/drawing/sketch')\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        for indicator in type_indicators[type]:\n",
    "            if indicator in text:\n",
    "                pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def save_indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        if type in save_indicators.keys():\n",
    "            for indicator in save_indicators[type]:\n",
    "                if indicator in text:\n",
    "                    pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine models via class-probability combination (soft-voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the full ds used for submission?\n",
    "full = True\n",
    "# submit to \n",
    "sub_name = 'three_models.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define models to be used for testing use 03 for submission use full\n",
    "import pickle\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('models/xg/full_smote100.json')\n",
    "\n",
    "rf = pickle.load(open('./models/rf/train_prep_full_best' , 'rb'))\n",
    "\n",
    "boost_emb = XGBClassifier()\n",
    "boost_emb.load_model('models/nlp/bal_full_xg_emb.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_prep.copy() if full else train_prep.copy()\n",
    "\n",
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)\n",
    "if full: X_test = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = X_test.index\n",
    "results.set_index('id', inplace=True)\n",
    "if not full: results['type'] = y_test\n",
    "\n",
    "#results['rf'] = rf.predict(X_test)\n",
    "#results['xg'] = xgb.predict_proba(X_test)\n",
    "\n",
    "results['filter'] = [-1] * len(results)\n",
    "results['indi'] = [-1] * len(results)\n",
    "results['save'] = [-1] * len(results)\n",
    "results['emb'] = [[-1]] * len(results)\n",
    "\n",
    "\n",
    "results['xg'] = [[-1]] * len(results)\n",
    "results['rf'] = [[-1]] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16679/1817881700.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['xg'].iloc[i] = np.array(item)\n",
      "/tmp/ipykernel_16679/1817881700.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['rf'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(xgb.predict_proba(X_test)):\n",
    "    results['xg'].iloc[i] = np.array(item)\n",
    "\n",
    "for i,item in enumerate(rf.predict_proba(X_test)):\n",
    "    results['rf'].iloc[i] = np.array(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_curie.copy() if full else train_curie.copy()\n",
    "\n",
    "features = text.drop('type', axis=1)\n",
    "labels = text.type\n",
    "\n",
    "#text['pred'] = boost_emb.predict_proba(features)\n",
    "text['pred'] = [[-1]] * len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16679/2524059003.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['pred'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(boost_emb.predict_proba(features)):\n",
    "    text['pred'].iloc[i] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# establish our own rules to determine type from text - eventually not beneficial\\ntext['filter'] = text.text_features.apply(filtering) # check for the type in the text\\ntext['indicating'] = text.text_features.apply(indicating) # check for other often occuring type indicating words\\ntext['save'] = text.text_features.apply(save_indicating) # only check for words that (almost) only occur with a certain type\\n\\ntext['filter'] = text['filter'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\ntext['indicating'] = text['indicating'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\ntext['save'] = text['save'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\\n\\nfor index, item in text.iterrows():\\n        if index in results.index:\\n            results.at[index, 'filter'] = item['filter']\\n            results.at[index, 'indi'] = item['indicating']\\n            results.at[index, 'save'] = item['save']\\n            results.at[index, 'emb'] = item['pred']\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# establish our own rules to determine type from text - eventually not beneficial\n",
    "text['filter'] = text.text_features.apply(filtering) # check for the type in the text\n",
    "text['indicating'] = text.text_features.apply(indicating) # check for other often occuring type indicating words\n",
    "text['save'] = text.text_features.apply(save_indicating) # only check for words that (almost) only occur with a certain type\n",
    "\n",
    "text['filter'] = text['filter'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['indicating'] = text['indicating'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "text['save'] = text['save'].apply(lambda x: type_lookup[type_lookup.english == x].index[0] if x != -1 else -1)\n",
    "\n",
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'filter'] = item['filter']\n",
    "            results.at[index, 'indi'] = item['indicating']\n",
    "            results.at[index, 'save'] = item['save']\n",
    "            results.at[index, 'emb'] = item['pred']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'emb'] = item['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evalaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def vote(preds):\n",
    "    if preds[-1][0] == -1:\n",
    "        preds = preds[:-1]\n",
    "    res = np.sum(preds, axis=0)\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['prediction'] = results.apply(lambda row: vote([row.xg,row.rf,row.emb]), axis=1)\n",
    "if not full:\n",
    "    print(accuracy_score(results.type, results.prediction))\n",
    "    print(classification_report(results.type, results.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == np.array([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full:\n",
    "    submission = pd.DataFrame({'id': results.index ,'type': results.prediction})\n",
    "    submission = submission.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "    submission.to_csv(f'submissions/{sub_name}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
