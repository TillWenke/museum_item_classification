{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "import re \n",
    "from math import isnan\n",
    "import wandb\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype={'type': str} prevents being confused with data type for large data sets\n",
    "train = pd.read_csv('data/train.csv', index_col='id', dtype={'type': str})\n",
    "test = pd.read_csv('data/test.csv', index_col='id', dtype={'type': str})\n",
    "train_translated = pd.read_csv('data/train_translated.csv', dtype={'type': str})\n",
    "test_translated = pd.read_csv('data/test_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data = pd.read_csv('data/combined_data.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_translated = pd.read_csv('data/combined_data_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_fully_translated = pd.read_csv('data/combined_data_fully_translated.csv', index_col='id', dtype={'type': str})\n",
    "prep = pd.read_csv('data/prep.csv', index_col='id', dtype={'type': str})\n",
    "test_prep = pd.read_csv('data/test_prepared.csv', index_col='id', dtype={'type': str})\n",
    "train_prep = pd.read_csv('data/train_prepared.csv', index_col='id', dtype={'type': str})\n",
    "low = pd.read_csv('data/prep_low_thres.csv', index_col='id', dtype={'type': str})\n",
    "high = pd.read_csv('data/prep_high_thres.csv', index_col='id', dtype={'type': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xg boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = high.copy()\n",
    "data = data[data.source=='train']\n",
    "data = data.drop(columns=['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_prep.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_type_<making/originating>\n",
      "material_photo material>photo paper\n",
      "material_photo material>photo paper>silver gelatin paper\n",
      "material_photographic material>emulsion>silver gelatin emulsion\n",
      "material_photographic material>film\n",
      "technique_photography>black and white photography\n"
     ]
    }
   ],
   "source": [
    "for i in high.columns:\n",
    "    if '>' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names must be string, and may not contain [, ] or <",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/xgboost_tries.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/xgboost_tries.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bst \u001b[39m=\u001b[39m XGBClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/xgboost_tries.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/xgboost_tries.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bst\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/xgboost_tries.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# make predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/xgboost_tries.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m preds \u001b[39m=\u001b[39m bst\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1497\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1488\u001b[0m (\n\u001b[1;32m   1489\u001b[0m     model,\n\u001b[1;32m   1490\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1496\u001b[0m )\n\u001b[0;32m-> 1497\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1498\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1499\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1500\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1501\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1502\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1503\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1504\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1505\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1506\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1507\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1508\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1509\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1510\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1511\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1512\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1513\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1514\u001b[0m )\n\u001b[1;32m   1516\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1517\u001b[0m     params,\n\u001b[1;32m   1518\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1528\u001b[0m )\n\u001b[1;32m   1530\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    430\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    446\u001b[0m     \u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:934\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:766\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_info(\n\u001b[1;32m    755\u001b[0m     label\u001b[39m=\u001b[39mlabel,\n\u001b[1;32m    756\u001b[0m     weight\u001b[39m=\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    762\u001b[0m     feature_weights\u001b[39m=\u001b[39mfeature_weights,\n\u001b[1;32m    763\u001b[0m )\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m feature_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39m=\u001b[39m feature_names\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m feature_types \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types \u001b[39m=\u001b[39m feature_types\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1164\u001b[0m, in \u001b[0;36mDMatrix.feature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[39m# prohibit to use symbols may affect to parse. e.g. []<\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m            \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(x \u001b[39min\u001b[39;00m f \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m((\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m   1163\u001b[0m            \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m feature_names):\n\u001b[0;32m-> 1164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mfeature_names must be string, and may not contain [, ] or <\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1165\u001b[0m feature_names_bytes \u001b[39m=\u001b[39m [\u001b[39mbytes\u001b[39m(f, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m feature_names]\n\u001b[1;32m   1166\u001b[0m c_feature_names \u001b[39m=\u001b[39m (ctypes\u001b[39m.\u001b[39mc_char_p \u001b[39m*\u001b[39m\n\u001b[1;32m   1167\u001b[0m                    \u001b[39mlen\u001b[39m(feature_names_bytes))(\u001b[39m*\u001b[39mfeature_names_bytes)\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names must be string, and may not contain [, ] or <"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier(random_state=0)\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007142857142857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc = accuracy_score(y_test, preds)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('models/xg/xgboost_full.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_prep.drop('type', axis=1)\n",
    "results = bst.predict(test_set)\n",
    "submission = pd.DataFrame({'id': test_set.index ,'type': bst.predict(test_set)})\n",
    "type_lookup = pd.read_csv('data/type_lookup.csv')\n",
    "submission = submission.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "submission.to_csv('data/submission_xgboost_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estonian = train.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = train_prep.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lookup = pd.DataFrame({'estonian': estonian, 'english': english})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lookup = type_lookup.sort_values(by='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lookup.reset_index(drop=True, inplace=True)\n",
    "type_lookup['id'] = type_lookup.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lookup.to_csv('data/type_lookup.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
