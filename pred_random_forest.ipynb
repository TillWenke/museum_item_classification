{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_general import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup data for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_est_prepared.copy()\n",
    "rebalancing = False\n",
    "\n",
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single rf classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to have resamplers resample to specific number of samples per class\n",
    "def by_num(data, min_samples):\n",
    "    b = Counter(y).values()\n",
    "    a = Counter(y).keys()\n",
    "    a = list(a)\n",
    "    b = list(b)\n",
    "\n",
    "    if min_samples > max(b):\n",
    "        min_samples = max(b)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        if b[i] < min_samples :\n",
    "            b[i] = min_samples\n",
    "    return dict(zip(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/pred_random_forest.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_random_forest.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m steps \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mover\u001b[39m\u001b[39m'\u001b[39m, over), (\u001b[39m'\u001b[39m\u001b[39munder\u001b[39m\u001b[39m'\u001b[39m, under), (\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m, rfc)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_random_forest.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipe \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39msteps)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_random_forest.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pipe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_random_forest.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m rfc\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/pred_random_forest.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m probs \u001b[39m=\u001b[39m rfc\u001b[39m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/pipeline.py:268\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[39mFit all the transforms/samplers one after the other and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    This estimator.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 268\u001b[0m Xt, yt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    269\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/pipeline.py:226\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m     X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    217\u001b[0m         cloned_transformer,\n\u001b[1;32m    218\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(cloned_transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_resample\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 226\u001b[0m     X, y, fitted_transformer \u001b[39m=\u001b[39m fit_resample_one_cached(\n\u001b[1;32m    227\u001b[0m         cloned_transformer,\n\u001b[1;32m    228\u001b[0m         X,\n\u001b[1;32m    229\u001b[0m         y,\n\u001b[1;32m    230\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    231\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    232\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/pipeline.py:394\u001b[0m, in \u001b[0;36m_fit_resample_one\u001b[0;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_resample_one\u001b[39m(sampler, X, y, message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    393\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m--> 394\u001b[0m         X_res, y_res \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mfit_resample(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    396\u001b[0m         \u001b[39mreturn\u001b[39;00m X_res, y_res, sampler\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/base.py:83\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[1;32m     85\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:324\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    321\u001b[0m X_class \u001b[39m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_k_\u001b[39m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 324\u001b[0m nns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn_k_\u001b[39m.\u001b[39;49mkneighbors(X_class, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m    325\u001b[0m X_new, y_new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_samples(\n\u001b[1;32m    326\u001b[0m     X_class, y\u001b[39m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[39m1.0\u001b[39m\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    328\u001b[0m X_resampled\u001b[39m.\u001b[39mappend(X_new)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:749\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    747\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    750\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    752\u001b[0m     )\n\u001b[1;32m    754\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    755\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "skf = StratifiedKFold(n_splits=4, random_state=0)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    over = SMOTE(sampling_strategy=by_num(y_train_fold,100), k_neighbors=3,random_state=0)\n",
    "    \n",
    "    steps = [('over', over),('model', rfc)]\n",
    "\n",
    "pipe = Pipeline(steps=steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "probs = rfc.predict_proba(X_test)\n",
    "val_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = rfc.predict(X_train)\n",
    "probs = rfc.predict_proba(X_train)\n",
    "train_acc = accuracy_score(y_train, y_pred)\n",
    "\n",
    "print(train_acc, val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sweeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'rf'\n",
    "\n",
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'split': {'values': [2, 5, 10, 100]},\n",
    "        'depth': {'values': [3, 6, 10, 50, 100, 1000]},\n",
    "        'leaf': {'values': [2, 6, 10, 50, 100, 1000, 5000]},\n",
    "        'estimators': {'values': [200, 500, 1000, 2000]},\n",
    "        'features': {'values': [None, 'sqrt', 'log2']},\n",
    "\n",
    "     }\n",
    "}\n",
    "\n",
    "# Initialize sweep by passing in config. (Optional) Provide a name of the project.\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=project)\n",
    "\n",
    "def main():\n",
    "    run = wandb.init(project=project)\n",
    "\n",
    "    # note that we define values from `wandb.config` instead \n",
    "    # of defining hard values \n",
    "    split = wandb.config.split\n",
    "    depth = wandb.config.depth\n",
    "    leaf = wandb.config.leaf\n",
    "    estimators = wandb.config.estimators\n",
    "    feat = wandb.config.features\n",
    "    \n",
    "\n",
    "    # -------------------------- usual training code starts here  -------------------------------------\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=estimators, max_depth=depth, min_samples_leaf=leaf, max_features=feat, min_samples_split=split, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    val_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    y_pred = rfc.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_pred)\n",
    "\n",
    "    print(train_acc, val_acc)\n",
    "\n",
    "    # -------------------------- ends here  -------------------------------------\n",
    "    \n",
    "\n",
    "    wandb.log({\n",
    "      'train_acc': train_acc,\n",
    "      'val_acc': val_acc,\n",
    "    })\n",
    "\n",
    "# Start sweep job.\n",
    "wandb.agent(sweep_id, function=main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rfc, open('./models/rf/train_prep_full_best', 'wb'))\n",
    "loaded_model = pickle.load(open('./models/rf/first_try', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_prep.drop('type', axis=1)\n",
    "submission = pd.DataFrame({'id': test_set.index ,'type': rfc.predict(test_set)})\n",
    "submission = submission.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "submission.to_csv('submissions/some_rf_model.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
