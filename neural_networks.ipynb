{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "import re \n",
    "from math import isnan\n",
    "import wandb\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype={'type': str} prevents being confused with data type for large data sets\n",
    "train = pd.read_csv('data/train.csv', index_col='id', dtype={'type': str})\n",
    "test = pd.read_csv('data/test.csv', index_col='id', dtype={'type': str})\n",
    "train_translated = pd.read_csv('data/train_translated.csv', dtype={'type': str})\n",
    "test_translated = pd.read_csv('data/test_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data = pd.read_csv('data/combined_data.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_translated = pd.read_csv('data/combined_data_translated.csv', index_col='id', dtype={'type': str})\n",
    "combined_data_fully_translated = pd.read_csv('data/combined_data_fully_translated.csv', index_col='id', dtype={'type': str})\n",
    "prep = pd.read_csv('data/prep.csv', index_col='id', dtype={'type': str})\n",
    "test_prep = pd.read_csv('data/test_prepared.csv', index_col='id', dtype={'type': str})\n",
    "train_prep = pd.read_csv('data/train_prepared.csv', index_col='id', dtype={'type': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_prep.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "# at least xgboost cannot deal with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(labels)\n",
    "labels = label_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/till/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.08797 | val_0_accuracy: 0.16405 |  0:00:01s\n",
      "epoch 1  | loss: 3.32842 | val_0_accuracy: 0.25619 |  0:00:03s\n",
      "epoch 2  | loss: 2.89253 | val_0_accuracy: 0.26429 |  0:00:05s\n",
      "epoch 3  | loss: 2.7657  | val_0_accuracy: 0.27    |  0:00:07s\n",
      "epoch 4  | loss: 2.60369 | val_0_accuracy: 0.31405 |  0:00:09s\n",
      "epoch 5  | loss: 2.3991  | val_0_accuracy: 0.31524 |  0:00:11s\n",
      "epoch 6  | loss: 2.16148 | val_0_accuracy: 0.38571 |  0:00:13s\n",
      "epoch 7  | loss: 2.02605 | val_0_accuracy: 0.46095 |  0:00:15s\n",
      "epoch 8  | loss: 1.87415 | val_0_accuracy: 0.51357 |  0:00:17s\n",
      "epoch 9  | loss: 1.74561 | val_0_accuracy: 0.55286 |  0:00:19s\n",
      "epoch 10 | loss: 1.61665 | val_0_accuracy: 0.57167 |  0:00:21s\n",
      "epoch 11 | loss: 1.4979  | val_0_accuracy: 0.57524 |  0:00:24s\n",
      "epoch 12 | loss: 1.37125 | val_0_accuracy: 0.60857 |  0:00:26s\n",
      "epoch 13 | loss: 1.2814  | val_0_accuracy: 0.59214 |  0:00:28s\n",
      "epoch 14 | loss: 1.1886  | val_0_accuracy: 0.61024 |  0:00:30s\n",
      "epoch 15 | loss: 1.1136  | val_0_accuracy: 0.63286 |  0:00:32s\n",
      "epoch 16 | loss: 1.04415 | val_0_accuracy: 0.665   |  0:00:34s\n",
      "epoch 17 | loss: 0.99097 | val_0_accuracy: 0.65667 |  0:00:36s\n",
      "epoch 18 | loss: 0.94945 | val_0_accuracy: 0.68    |  0:00:38s\n",
      "epoch 19 | loss: 0.87419 | val_0_accuracy: 0.6731  |  0:00:40s\n",
      "epoch 20 | loss: 0.82862 | val_0_accuracy: 0.70357 |  0:00:42s\n",
      "epoch 21 | loss: 0.78358 | val_0_accuracy: 0.72262 |  0:00:44s\n",
      "epoch 22 | loss: 0.74585 | val_0_accuracy: 0.73143 |  0:00:46s\n",
      "epoch 23 | loss: 0.72134 | val_0_accuracy: 0.74143 |  0:00:48s\n",
      "epoch 24 | loss: 0.70101 | val_0_accuracy: 0.74238 |  0:00:51s\n",
      "epoch 25 | loss: 0.67581 | val_0_accuracy: 0.76143 |  0:00:53s\n",
      "epoch 26 | loss: 0.65705 | val_0_accuracy: 0.77024 |  0:00:56s\n",
      "epoch 27 | loss: 0.64485 | val_0_accuracy: 0.77286 |  0:00:58s\n",
      "epoch 28 | loss: 0.6284  | val_0_accuracy: 0.76048 |  0:01:01s\n",
      "epoch 29 | loss: 0.61658 | val_0_accuracy: 0.76429 |  0:01:03s\n",
      "epoch 30 | loss: 0.60708 | val_0_accuracy: 0.76548 |  0:01:06s\n",
      "epoch 31 | loss: 0.58003 | val_0_accuracy: 0.78476 |  0:01:08s\n",
      "epoch 32 | loss: 0.56549 | val_0_accuracy: 0.7831  |  0:01:10s\n",
      "epoch 33 | loss: 0.55238 | val_0_accuracy: 0.78571 |  0:01:13s\n",
      "epoch 34 | loss: 0.52676 | val_0_accuracy: 0.79071 |  0:01:15s\n",
      "epoch 35 | loss: 0.52262 | val_0_accuracy: 0.79548 |  0:01:17s\n",
      "epoch 36 | loss: 0.51743 | val_0_accuracy: 0.79667 |  0:01:20s\n",
      "epoch 37 | loss: 0.51546 | val_0_accuracy: 0.81214 |  0:01:22s\n",
      "epoch 38 | loss: 0.50534 | val_0_accuracy: 0.80524 |  0:01:24s\n",
      "epoch 39 | loss: 0.50845 | val_0_accuracy: 0.81571 |  0:01:27s\n",
      "epoch 40 | loss: 0.49836 | val_0_accuracy: 0.8181  |  0:01:29s\n",
      "epoch 41 | loss: 0.49382 | val_0_accuracy: 0.81405 |  0:01:32s\n",
      "epoch 42 | loss: 0.47693 | val_0_accuracy: 0.81667 |  0:01:34s\n",
      "epoch 43 | loss: 0.47628 | val_0_accuracy: 0.82214 |  0:01:36s\n",
      "epoch 44 | loss: 0.46829 | val_0_accuracy: 0.83    |  0:01:39s\n",
      "epoch 45 | loss: 0.46679 | val_0_accuracy: 0.8319  |  0:01:41s\n",
      "epoch 46 | loss: 0.45877 | val_0_accuracy: 0.82881 |  0:01:43s\n",
      "epoch 47 | loss: 0.45263 | val_0_accuracy: 0.82833 |  0:01:46s\n",
      "epoch 48 | loss: 0.44987 | val_0_accuracy: 0.82524 |  0:01:48s\n",
      "epoch 49 | loss: 0.4558  | val_0_accuracy: 0.84262 |  0:01:50s\n",
      "epoch 50 | loss: 0.45711 | val_0_accuracy: 0.83619 |  0:01:52s\n",
      "epoch 51 | loss: 0.44904 | val_0_accuracy: 0.84048 |  0:01:54s\n",
      "epoch 52 | loss: 0.4445  | val_0_accuracy: 0.84024 |  0:01:56s\n",
      "epoch 53 | loss: 0.43873 | val_0_accuracy: 0.84381 |  0:01:59s\n",
      "epoch 54 | loss: 0.42198 | val_0_accuracy: 0.83929 |  0:02:01s\n",
      "epoch 55 | loss: 0.41683 | val_0_accuracy: 0.84333 |  0:02:03s\n",
      "epoch 56 | loss: 0.42147 | val_0_accuracy: 0.8469  |  0:02:05s\n",
      "epoch 57 | loss: 0.41871 | val_0_accuracy: 0.84548 |  0:02:07s\n",
      "epoch 58 | loss: 0.4223  | val_0_accuracy: 0.84452 |  0:02:09s\n",
      "epoch 59 | loss: 0.41542 | val_0_accuracy: 0.84548 |  0:02:12s\n",
      "epoch 60 | loss: 0.403   | val_0_accuracy: 0.85119 |  0:02:14s\n",
      "epoch 61 | loss: 0.41147 | val_0_accuracy: 0.85214 |  0:02:16s\n",
      "epoch 62 | loss: 0.40053 | val_0_accuracy: 0.85095 |  0:02:19s\n",
      "epoch 63 | loss: 0.40484 | val_0_accuracy: 0.84976 |  0:02:21s\n",
      "epoch 64 | loss: 0.38965 | val_0_accuracy: 0.8531  |  0:02:24s\n",
      "epoch 65 | loss: 0.40571 | val_0_accuracy: 0.84786 |  0:02:26s\n",
      "epoch 66 | loss: 0.40091 | val_0_accuracy: 0.85095 |  0:02:28s\n",
      "epoch 67 | loss: 0.3907  | val_0_accuracy: 0.84786 |  0:02:31s\n",
      "epoch 68 | loss: 0.38138 | val_0_accuracy: 0.85048 |  0:02:33s\n",
      "epoch 69 | loss: 0.38736 | val_0_accuracy: 0.855   |  0:02:35s\n",
      "epoch 70 | loss: 0.38255 | val_0_accuracy: 0.85452 |  0:02:38s\n",
      "epoch 71 | loss: 0.37886 | val_0_accuracy: 0.85119 |  0:02:40s\n",
      "epoch 72 | loss: 0.37607 | val_0_accuracy: 0.85214 |  0:02:42s\n",
      "epoch 73 | loss: 0.3717  | val_0_accuracy: 0.85524 |  0:02:45s\n",
      "epoch 74 | loss: 0.35616 | val_0_accuracy: 0.86024 |  0:02:47s\n",
      "epoch 75 | loss: 0.36636 | val_0_accuracy: 0.85714 |  0:02:49s\n",
      "epoch 76 | loss: 0.37298 | val_0_accuracy: 0.85905 |  0:02:52s\n",
      "epoch 77 | loss: 0.35345 | val_0_accuracy: 0.85571 |  0:02:54s\n",
      "epoch 78 | loss: 0.3519  | val_0_accuracy: 0.85857 |  0:02:57s\n",
      "epoch 79 | loss: 0.34486 | val_0_accuracy: 0.85548 |  0:02:59s\n",
      "epoch 80 | loss: 0.34882 | val_0_accuracy: 0.85143 |  0:03:01s\n",
      "epoch 81 | loss: 0.35027 | val_0_accuracy: 0.85881 |  0:03:04s\n",
      "epoch 82 | loss: 0.3565  | val_0_accuracy: 0.85667 |  0:03:06s\n",
      "epoch 83 | loss: 0.34767 | val_0_accuracy: 0.85738 |  0:03:08s\n",
      "epoch 84 | loss: 0.34694 | val_0_accuracy: 0.85786 |  0:03:10s\n",
      "epoch 85 | loss: 0.35238 | val_0_accuracy: 0.85262 |  0:03:12s\n",
      "epoch 86 | loss: 0.36804 | val_0_accuracy: 0.85619 |  0:03:14s\n",
      "epoch 87 | loss: 0.35486 | val_0_accuracy: 0.85643 |  0:03:17s\n",
      "epoch 88 | loss: 0.35982 | val_0_accuracy: 0.84976 |  0:03:19s\n",
      "epoch 89 | loss: 0.37141 | val_0_accuracy: 0.8519  |  0:03:21s\n",
      "epoch 90 | loss: 0.35392 | val_0_accuracy: 0.85643 |  0:03:23s\n",
      "epoch 91 | loss: 0.35683 | val_0_accuracy: 0.85333 |  0:03:26s\n",
      "epoch 92 | loss: 0.34342 | val_0_accuracy: 0.85095 |  0:03:28s\n",
      "epoch 93 | loss: 0.3474  | val_0_accuracy: 0.85024 |  0:03:30s\n",
      "epoch 94 | loss: 0.33115 | val_0_accuracy: 0.85286 |  0:03:33s\n",
      "epoch 95 | loss: 0.32213 | val_0_accuracy: 0.85238 |  0:03:35s\n",
      "epoch 96 | loss: 0.32117 | val_0_accuracy: 0.8519  |  0:03:37s\n",
      "epoch 97 | loss: 0.30859 | val_0_accuracy: 0.85071 |  0:03:40s\n",
      "epoch 98 | loss: 0.31106 | val_0_accuracy: 0.85071 |  0:03:42s\n",
      "epoch 99 | loss: 0.31385 | val_0_accuracy: 0.85167 |  0:03:45s\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/neural_networks.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf \u001b[39m=\u001b[39m TabNetClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   X_train\u001b[39m.\u001b[39mvalues, y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   eval_set\u001b[39m=\u001b[39m[(X_test\u001b[39m.\u001b[39mvalues, y_test)], patience\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m preds \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/neural_networks.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m probs \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:284\u001b[0m, in \u001b[0;36mTabModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    277\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    278\u001b[0m     PredictDataset(X),\n\u001b[1;32m    279\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    280\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    281\u001b[0m )\n\u001b[1;32m    283\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 284\u001b[0m \u001b[39mfor\u001b[39;00m batch_nb, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m    285\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    286\u001b[0m     output, M_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_tabnet/utils.py:53\u001b[0m, in \u001b[0;36mPredictDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m---> 53\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[index]\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(\n",
    "  X_train.values, y_train,\n",
    "  eval_set=[(X_test.values, y_test)], patience=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X_test.values)\n",
    "probs = clf.predict_proba(X_test.values)\n",
    "val_acc = accuracy_score(y_test, preds)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at models/nn/first_try.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/nn/first_try.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.save_model('models/nn/first_try')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
